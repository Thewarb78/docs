sudo apt update
sudo apt upgrade -y

sudo apt install -y ca-certificates curl gnupg lsb-release

sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

sudo docker --version
sudo docker run hello-world

test

####

{
  "proxies": {
    "default": {
      "httpProxy": "http://your.proxy.server:port",
      "httpsProxy": "http://your.proxy.server:port",
      "noProxy": "localhost,127.0.0.1,::1"
    }
  }
}

####


Build and then run the flask:

docker build -t flask-app:latest .

docker run --network=my_network -p 5000:5000 --name flask-app flask-app

Running with the env vars for mongo pw specified in env vars:

docker run --network=my_network -p 5000:5000   -e MONGO_USERNAME=admin -e MONGO_PASSWORD=*** -e MONGO_HOST=29471c688f24 -e MONGO_DB=reportsdb--name flask-app 

####

FROM ubuntu:latest  # Or ubuntu:20.04, ubuntu:22.04, etc.

# Install Python 3.9 and dependencies
RUN apt update && apt install -y software-properties-common && \
    add-apt-repository ppa:deadsnakes/ppa -y && \
    apt update && apt install -y python3.9 python3.9-venv python3.9-dev python3.9-distutils curl && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3.9

# Set Python 3.9 as default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2 && \
    update-alternatives --set python3 /usr/bin/python3.9

# Verify
RUN python3 --version && pip3 --version


####

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({"status": "ok"}), 200

####

import pytest
from app import app  # Adjust the import if your app file has a different name

@pytest.fixture
def client():
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_health_check(client):
    response = client.get('/health')
    assert response.status_code == 200
    assert response.get_json() == {"status": "ok"}

#####


pipeline {
    agent any

    environment {
        ARTIFACTORY_URL = 'https://your-artifactory.com'
        ARTIFACTORY_REPO_DEV = 'docker-local-dev'
        ARTIFACTORY_REPO_RELEASE = 'docker-local-release'
        IMAGE_NAME = 'your-app'
        ARTIFACTORY_USER = credentials('artifactory-user')
        ARTIFACTORY_PASSWORD = credentials('artifactory-password')

        ENVIRONMENT = sh(script: '''
            case "$JOB_NAME" in
                *dev*) echo "dev" ;;
                *stg*) echo "stg" ;;
                *prd*) echo "prd" ;;
                *) echo "unknown" ;;
            esac
        ''', returnStdout: true).trim()
    }

    stages {
        stage('Debug: Show Environment') {
            steps {
                script {
                    echo "üîç DEBUG: Detected Environment: ${env.ENVIRONMENT}"
                }
            }
        }

        stage('Build & Push Dev (Auto)') {
            when { expression { env.ENVIRONMENT == 'dev' } }
            steps {
                script {
                    def server = Artifactory.newServer url: ARTIFACTORY_URL
                    def rtDocker = Artifactory.docker server: server
                    def devTag = "${ARTIFACTORY_REPO_DEV}/${IMAGE_NAME}:latest-dev"

                    def buildInfo = rtDocker.push("${devTag}", forceXrayScan: true)
                    server.publishBuildInfo buildInfo
                    echo "‚úÖ Dev image pushed as latest-dev (overwritten)."
                }
            }
        }

        stage('Promote to Staging (Gated)') {
            when { expression { env.ENVIRONMENT == 'stg' } }
            steps {
                script {
                    def server = Artifactory.newServer url: ARTIFACTORY_URL
                    def promotionConfig = [
                        'targetRepo': ARTIFACTORY_REPO_RELEASE,
                        'dockerRepository': IMAGE_NAME,
                        'tag': 'latest-dev',
                        'targetTag': 'latest-stg',
                        'copy': true
                    ]

                    server.dockerPromote promotionConfig
                    echo "‚úÖ Staging image promoted from latest-dev to latest-stg."
                }
            }
        }

        stage('Verify Staging Deployment Before Prod') {
            when { expression { env.ENVIRONMENT == 'prd' } }
            steps {
                script {
                    echo "üîç Checking if latest-stg exists before proceeding to Production..."
                    def stgExists = sh(script: """
                        curl -s -u ${ARTIFACTORY_USER}:${ARTIFACTORY_PASSWORD} \\
                             -X GET "${ARTIFACTORY_URL}/artifactory/api/docker/${ARTIFACTORY_REPO_RELEASE}/v2/${IMAGE_NAME}/manifests/latest-stg" \\
                             -o /dev/null -w "%{http_code}"
                    """, returnStdout: true).trim()

                    if (stgExists != "200") {
                        error "‚ùå ERROR: Staging image does not exist in Artifactory. Cannot proceed to production."
                    }

                    echo "‚úÖ Staging image exists. Proceeding to Production."
                }
            }
        }

        stage('Promote to Production (Gated)') {
            when { expression { env.ENVIRONMENT == 'prd' } }
            steps {
                script {
                    def server = Artifactory.newServer url: ARTIFACTORY_URL
                    def promotionConfig = [
                        'targetRepo': ARTIFACTORY_REPO_RELEASE,
                        'dockerRepository': IMAGE_NAME,
                        'tag': 'latest-stg', // ‚úÖ Copy Staging, not Dev!
                        'targetTag': 'latest-prd',
                        'copy': true
                    ]

                    server.dockerPromote promotionConfig
                    echo "‚úÖ Production image copied from latest-stg to latest-prd."
                }
            }
        }
    }

    post {
        success {
            echo "üéâ Pipeline completed successfully for ${env.ENVIRONMENT}!"
        }
        failure {
            echo "‚ùå Pipeline failed for ${env.ENVIRONMENT}. Check logs."
        }
    }
}

####

Get Details of Blocking Queries

SELECT 
    r.session_id, 
    r.blocking_session_id, 
    r.wait_type, 
    r.wait_time / 1000 AS WaitTimeSec, 
    r.wait_resource, 
    t.text AS SQLQuery
FROM sys.dm_exec_requests r
CROSS APPLY sys.dm_exec_sql_text(r.sql_handle) t
WHERE r.blocking_session_id <> 0;

####

Find Queries Currently Running in the Usage Database

USE WSS_UsageApplication; -- Change to your SharePoint DB
GO

SELECT 
    r.session_id, 
    r.status, 
    r.command, 
    r.wait_type, 
    r.wait_time / 1000 AS WaitTimeSec, 
    r.blocking_session_id, 
    t.text AS SQLQuery
FROM sys.dm_exec_requests r
CROSS APPLY sys.dm_exec_sql_text(r.sql_handle) t
WHERE r.database_id = DB_ID();

####

Find the Most Blocked Queries (Historical Data)

SELECT 
    blocking_session_id AS BlockingSession, 
    COUNT(*) AS BlockedQueries
FROM sys.dm_exec_requests
WHERE blocking_session_id <> 0
GROUP BY blocking_session_id
ORDER BY COUNT(*) DESC;

####

Find the Largest Tables in the Usage DB (Possible Cause of Blocking)

USE WSS_UsageApplication; -- Change this to your Usage DB
GO

SELECT 
    t.NAME AS TableName, 
    p.rows AS RowCounts, 
    SUM(a.total_pages) * 8 / 1024 AS TotalSpaceMB
FROM sys.tables t
JOIN sys.indexes i ON t.OBJECT_ID = i.object_id
JOIN sys.partitions p ON i.object_id = p.OBJECT_ID AND i.index_id = p.index_id
JOIN sys.allocation_units a ON p.partition_id = a.container_id
GROUP BY t.Name, p.Rows
ORDER BY TotalSpaceMB DESC;

import requests

def getOAuthAccessToken(host, endpoint, basicAuthString):
    url = f"https://{host}{endpoint}"  # Construct full URL
    payload = {'grant_type': 'client_credentials'}  # Use a dictionary for form data
    headers = {
        'Content-Type': 'application/x-www-form-urlencoded',
        'Authorization': basicAuthString
    }

    # Make the POST request
    response = requests.post(url, data=payload, headers=headers)

    # Raise an error if the request fails
    response.raise_for_status()

    # Parse JSON response
    json_data = response.json()

    # Return access token
    return json_data.get("access_token", None)

def makeBearerCall(host, token, verb, endpoint):
    url = f"https://{host}{endpoint}"  # Construct full URL
    headers = {
        'Authorization': f'Bearer {token}'
    }

    # Make the request with the specified HTTP verb
    response = requests.request(verb, url, headers=headers)

    # Raise an error if the request fails
    response.raise_for_status()

    # Return response content as text
    return response.text

    import requests
import json

# Define the URL of the web service
url = "https://example.com/api/data"  # Replace with the actual API endpoint

try:
    # Make a GET request to the web service
    response = requests.get(url)

    # Ensure the request was successful
    response.raise_for_status()

    # Parse the JSON response
    data = response.json()

    # Print the parsed JSON data in a structured format
    for entry in data:
        print(f"SUB ID: {entry.get('SUB ID', 'N/A')}")
        print(f"SERVER: {entry.get('SERVER', 'N/A')}")
        print(f"ECOSYSTEM: {entry.get('ECOSYSTEM', 'N/A')}")
        print("-" * 30)

except requests.exceptions.RequestException as e:
    print(f"Error fetching data: {e}")
except json.JSONDecodeError:
    print("Error parsing JSON response")

import requests

url = "https://your-api-endpoint.com"  # Replace with actual API URL
try:
    response = requests.get(url)
    response.raise_for_status()
except requests.exceptions.SSLError as e:
    print(f"SSL Error: {e}")
except requests.exceptions.RequestException as e:
    print(f"Request failed: {e}")

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.ssl_ import create_urllib3_context

class TLSAdapter(HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        ctx = create_urllib3_context()
        ctx.minimum_version = 3  # Forces TLS 1.2 or higher
        kwargs['ssl_context'] = ctx
        super().init_poolmanager(*args, **kwargs)

session = requests.Session()
session.mount("https://", TLSAdapter())

url = "https://your-api-endpoint.com"
response = session.get(url, verify=False)  # Set verify=False only for debugging
print(response.text)

[System.Net.WebRequest]::DefaultWebProxy = New-Object System.Net.WebProxy("http://proxyserver:8080", $true)
[System.Net.WebRequest]::DefaultWebProxy.Credentials = [System.Net.CredentialCache]::DefaultCredentials


sudo nano /etc/systemd/system/mycontainer.service

[Unit]
Description=My Docker Container
After=network.target

[Service]
ExecStartPre=-/usr/bin/docker pull your-image:latest
ExecStart=/usr/bin/docker run --rm --name mycontainer -p 8080:8080 -d your-image:latest
ExecStop=/usr/bin/docker stop mycontainer
Restart=always

[Install]
WantedBy=multi-user.target

sudo systemctl daemon-reload
sudo systemctl enable mycontainer
sudo systemctl start mycontainer

######

from flask import Flask, request, jsonify, render_template, send_file, redirect, url_for
from flask_pymongo import PyMongo
from flask_oidc import OpenIDConnect
from bson.objectid import ObjectId
from datetime import datetime
import os
import pandas as pd
from io import BytesIO

app = Flask(__name__)

# --- OIDC Config ---
app.config.update({
    'SECRET_KEY': 'super-secret-key',  # Replace with your own secret
    'OIDC_CLIENT_SECRETS': 'client_secrets.json',
    'OIDC_SCOPES': ['openid', 'email', 'profile'],
    'OIDC_RESOURCE_CHECK_AUD': True,
    'OIDC_INTROSPECTION_AUTH_METHOD': 'client_secret_post',
    'OVERWRITE_REDIRECT_URI': 'http://localhost:5000/oidc/callback'  # Update in production
})
oidc = OpenIDConnect(app)

# --- MongoDB Config ---
app.config["MONGO_URI"] = "mongodb://admin:@localhost:27017/reportsdb?authSource=admin"
mongo = PyMongo(app)
reports_collection = mongo.db.reports

# --- Auth routes ---
@app.route('/login')
@oidc.require_login
def login():
    return redirect(url_for('view_reports'))

@app.route('/logout')
def logout():
    oidc.logout()
    return redirect(url_for('view_reports'))

# --- UI route (protected) ---
@app.route('/reports/view', methods=['GET'])
@oidc.require_login
def view_reports():
    # (existing logic for view_reports goes here)
    return render_template('view_reports.html')

# --- OIDC callback ---
@app.route('/oidc/callback')
def oidc_callback():
    return redirect(url_for('view_reports'))

if __name__ == '__main__':
    app.run(debug=True)

#####

{
  "web": {
    "client_id": "flask-ui-client",
    "client_secret": "YOUR_CLIENT_SECRET",
    "auth_uri": "https://your-oidc-provider/auth",
    "token_uri": "https://your-oidc-provider/token",
    "userinfo_uri": "https://your-oidc-provider/userinfo",
    "issuer": "https://your-oidc-provider/",
    "redirect_uris": [
      "http://localhost:5000/oidc/callback"
    ]
  }
}

<link rel="icon" type="image/png" href="{{ url_for('static', filename='mf-favicon.png') }}">

##

# Load SharePoint snapin if needed
if ((Get-PSSnapin -Name Microsoft.SharePoint.PowerShell -ErrorAction SilentlyContinue) -eq $null) {
    Add-PSSnapin Microsoft.SharePoint.PowerShell
}

# Variables
$siteUrl = "http://your-sharepoint-site"
$libraryName = "Documents"

# Connect
$site = Get-SPSite $siteUrl
$web = $site.RootWeb
$list = $web.Lists[$libraryName]

# Function to count folders recursively
function Get-FolderCount {
    param (
        [Microsoft.SharePoint.SPFolder]$Folder
    )

    $folderCount = 0

    foreach ($subFolder in $Folder.SubFolders) {
        if ($subFolder.Name -ne "Forms") { # Skip system folders
            $folderCount++
            $folderCount += Get-FolderCount -Folder $subFolder
        }
    }

    return $folderCount
}

# Start counting from root folder
$totalFolders = Get-FolderCount -Folder $list.RootFolder

Write-Host "Total number of folders in library '$libraryName': $totalFolders"

# Cleanup
$web.Dispose()
$site.Dispose()

####

SELECT 
    DocId,
    COUNT(*) AS VersionCount,
    MAX(Version) AS MaxVersion,
    LeafName,
    DirName
FROM 
    AllDocVersions WITH (NOLOCK)
WHERE 
    LeafName LIKE '%.one%' AND
    DirName LIKE 'sites/marketing%'  -- Adjust to your site's path
GROUP BY 
    DocId, LeafName, DirName
ORDER BY 
    VersionCount DESC;

###

SELECT COUNT(*) AS VersionRowCount
FROM AllDocVersions WITH (NOLOCK)
WHERE SiteId = 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx';

Add-PSSnapin Microsoft.SharePoint.PowerShell -ErrorAction SilentlyContinue

$results = @()

$sites = Get-SPSite -Limit All

foreach ($site in $sites) {
    try {
        # Check if the Publishing feature is activated at the Site Collection level
        $siteFeatures = Get-SPFeature -Site $site -ErrorAction SilentlyContinue
        if ($siteFeatures.DisplayName -contains "PublishingSite") {
            $results += [PSCustomObject]@{
                Url      = $site.Url
                Level    = "Site Collection"
                Feature  = "PublishingSite"
            }
        }

        foreach ($web in $site.AllWebs) {
            try {
                $webFeatures = Get-SPFeature -Web $web -ErrorAction SilentlyContinue
                if ($webFeatures.DisplayName -contains "PublishingWeb") {
                    $results += [PSCustomObject]@{
                        Url      = $web.Url
                        Level    = "Web"
                        Feature  = "PublishingWeb"
                    }
                }
            } catch {
                Write-Warning "Error accessing web: $($_.Exception.Message)"
            } finally {
                $web.Dispose()
            }
        }

    } catch {
        Write-Warning "Error accessing site collection: $($_.Exception.Message)"
    } finally {
        $site.Dispose()
    }
}

# Output results
$results | Format-Table -AutoSize

# Optional: Export to CSV
$results | Export-Csv "C:\Temp\PublishingSites.csv" -NoTypeInformation

Write-Host "‚úÖ Finished scanning for publishing-enabled sites." -ForegroundColor Green


###
Add-PSSnapin Microsoft.SharePoint.PowerShell -ErrorAction SilentlyContinue

# Build the override dictionary and category name list
$overrideDictionary = @{}
$keyList = @()

$svc = [Microsoft.SharePoint.Administration.SPDiagnosticsService]::Local

foreach ($area in $svc.Areas) {
    foreach ($category in $area.Categories) {
        $fullName = "$($area.Name)\$($category.Name)"
        if (-not $overrideDictionary.ContainsKey($fullName)) {
            $overrideDictionary[$fullName] = $category.TraceSeverity
            $keyList += $fullName
        }
    }
}

Write-Host "`nTotal diagnostic categories loaded: $($keyList.Count)"
Write-Host "Simulating dictionary lookups..."

# Simulate dictionary lookup (like TraceLevelOverrideStop does internally)
$sw = [System.Diagnostics.Stopwatch]::StartNew()

foreach ($key in $keyList) {
    $null = $overrideDictionary[$key]
}

$sw.Stop()

Write-Host "`n‚úÖ Simulation complete"
Write-Host "‚è± Lookup time: $($sw.ElapsedMilliseconds) ms"
Write-Host "üîç Keys checked: $($keyList.Count)"
Write-Host "üì¶ Dictionary size: $($overrideDictionary.Count)"

####

$targetTime = Get-Date "2025-06-20 14:10"
$before = $targetTime.AddMinutes(5)
$after = $targetTime.AddMinutes(-5)

Get-SPTimerJob | Where-Object {
    $_.LastRunTime -ge $after -and $_.LastRunTime -le $before
} | Select DisplayName, LastRunTime, TypeName

###

Title:
High CPU usage in w3wp.exe and owstimer.exe following SharePoint 2016 patch (16.0.5478.1000), linked to ULS.SendTrace and Dictionary.TryGetValue

üß© Problem Overview:
Since deploying the March 2024 CU (build 16.0.5478.1000) to our SharePoint 2016 farms, we have observed intermittent but severe CPU spikes, impacting both:

w3wp.exe worker processes (App Pools)

owstimer.exe (SharePoint Timer Service)

The behavior is consistent across multiple farms, in different geographic regions, with different AV policies and different usage patterns ‚Äî but all running Server 2019 and patched to this build.

üîç Observed Technical Behavior:
1. w3wp.exe High CPU (App Pools)
Spikes are traced in Dynatrace to:

ULS.SendTrace

TraceRaiseEventMgdHandler

.NET Dictionary<TKey,TValue>.TryGetValue

CPU usage occurs even with:

Default logging levels

No custom trace categories

Publishing-related logging disabled

Affected categories include SharePoint.Publishing, but also others, suggesting a global trace evaluation issue, not just one area.

2. owstimer.exe CPU Spikes
owstimer.exe intermittently shows similar high CPU usage

Not instrumented in Dynatrace ‚Äî but we observed logging activity to:

C:\Users\...\AppData\Local\Temp\DCacheAdministration...

Suggests Distributed Cache or configuration-related timer jobs are triggering trace logic internally

ULS logs show the same Dictionary.TryGetValue activity in ULS.SendTrace

‚ùå What We've Ruled Out
Potential Cause	Status
AV interference	‚ùå Ruled out ‚Äî proper exclusions confirmed across all farms
Excessive trace volume	‚ùå Logging set to None for all categories ‚Äî issue persists
Misconfigured logging overrides	‚ùå Clear-SPLogLevel run; all log levels confirmed at default
Custom solutions	‚úÖ We have reviewed deployed WSPs and nothing changed recently
Publishing alone	‚ùå Disabling Publishing logging had no effect
Timer job misfire	üü° Inconclusive, but no unusual jobs found in logs during spikes

üß™ Conclusion / Hypothesis
There appears to be a regression in trace logging logic introduced by the March 2024 CU, whereby:

Logging category dictionary evaluations are invoked on every request, or background job

These dictionary lookups are not efficiently cached, or are being repeatedly re-evaluated

It impacts trace path evaluation, even when logging output is fully disabled

The behavior did not occur prior to this patch and is only present on Server 2019 hosts

üìù What We Need from Microsoft
Confirmation of changes to trace evaluation, logging override logic, or diagnostic infrastructure in/around 16.0.5478.1000

Review of known issues involving:

ULS.SendTrace

SPDiagnosticsServiceBase

Publishing modules and trace categories

Suggested hotfix or rollback plan (if applicable)

A reproducible scenario (or test guidance) we can use to confirm this without impacting live usage

üí¨ Optional Additional Notes
Some affected endpoints during spikes: sites.asmx, sharedaccess.asmx, GetUpdatedFormDigest

We attempted to trigger the issue via synthetic traffic to publishing sites ‚Äî no immediate effect

The farms are otherwise stable, but trace-related CPU overhead is degrading performance significantly

###

# Load SharePoint snap-in if not already loaded
if ((Get-PSSnapin -Name Microsoft.SharePoint.PowerShell -ErrorAction SilentlyContinue) -eq $null) {
    Add-PSSnapin Microsoft.SharePoint.PowerShell
}

# Get all logging categories
$allCategories = Get-SPLogLevel

# Loop through and set the levels
foreach ($category in $allCategories) {
    Set-SPLogLevel -TraceSeverity High -EventSeverity Error -Area $category.Area -Name $category.Name
}

Write-Host "All logging categories updated: TraceSeverity = High, EventSeverity = Error"

###

$logRoot = "C:\ProgramData\dynatrace\oneagent\log"
$since = (Get-Date).AddDays(-1)
$keywords = @("LogRequest", "timeout", "PurePath", "span", "callback", "Async", "Exception", "flush", "export", "took", "duration")

# Get all log files modified in the last day
$logFiles = Get-ChildItem -Path $logRoot -Recurse -Include *.log -File |
    Where-Object { $_.LastWriteTime -gt $since }

foreach ($file in $logFiles) {
    try {
        $lines = Get-Content $file.FullName
        $matches = $lines | Where-Object {
            $line = $_.ToLower()
            $keywords | ForEach-Object { $line -like "*$_*" }
        }
        if ($matches) {
            Write-Host "`n===== Matches in $($file.FullName) =====" -ForegroundColor Cyan
            $matches | ForEach-Object { Write-Host $_ -ForegroundColor Yellow }
        }
    }
    catch {
        Write-Warning "Failed to read $($file.FullName): $_"
    }
}

"applicationMatchRules": [
  {
    "applicationMatchType": "MATCHES",
    "matchers": [
      {
        "matcherType": "DOMAIN",
        "value": "app1.example.com"
      },
      {
        "matcherType": "URL_STARTS_WITH",
        "value": "https://example.com/path"
      }
    ]
  }
]

#####

# CONFIG
$logFile = "C:\Logs\AD_HealthMonitor.log"
$intervalSeconds = 60
$domainName = (Get-WmiObject Win32_ComputerSystem).Domain

# Ensure log folder exists
$logFolder = [System.IO.Path]::GetDirectoryName($logFile)
if (!(Test-Path $logFolder)) {
    New-Item -ItemType Directory -Path $logFolder | Out-Null
}

Write-Host "Starting AD health monitor loop. Logging to $logFile"

while ($true) {
    $timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
    $dc = "UNKNOWN"
    $ldapTime = "N/A"
    $nltestDc = "UNKNOWN"
    $nltestError = $null
    $siteName = (nltest /dsgetsite 2>&1)[0].Trim()

    try {
        # Get domain controller via .NET
        $domain = [System.DirectoryServices.ActiveDirectory.Domain]::GetCurrentDomain()
        $dc = $domain.PdcRoleOwner.Name

        # LDAP query timing
        $sw = [System.Diagnostics.Stopwatch]::StartNew()
        $searcher = New-Object System.DirectoryServices.DirectorySearcher
        $searcher.Filter = "(objectClass=user)"
        $searcher.PageSize = 1
        $result = $searcher.FindOne()
        $sw.Stop()
        $ldapTime = $sw.ElapsedMilliseconds
        $status = if ($result) { "OK" } else { "NoResult" }

    } catch {
        $status = "LDAP_FAIL: $($_.Exception.Message)"
    }

    try {
        # Get DC info using nltest
        $nltestOutput = nltest /dsgetdc:$domainName 2>&1
        if ($LASTEXITCODE -eq 0) {
            $nltestDc = ($nltestOutput | Select-String "DC:" | ForEach-Object { ($_ -split ":")[1].Trim() })[0]
        } else {
            $nltestError = $nltestOutput -join " "
        }
    } catch {
        $nltestError = $_.Exception.Message
    }

    $logLine = "$timestamp | AD Site: $siteName | PDC: $dc | LDAP: ${ldapTime}ms | Status: $status | NLTEST_DC: $nltestDc"

    if ($nltestError) {
        $logLine += " | NLTEST_ERR: $nltestError"
    }

    Add-Content -Path $logFile -Value $logLine
    Write-Host $logLine

    Start-Sleep -Seconds $intervalSeconds
}

###

# CONFIG
$logFile = "C:\Logs\AD_HealthMonitor_EnsureUser.log"
$intervalSeconds = 60
$domainName = (Get-WmiObject Win32_ComputerSystem).Domain
$siteName = (nltest /dsgetsite 2>&1)[0].Trim()
$webUrl = "https://your.site.url"
$usersToCheck = @(
    "i:0#.w|DOMAIN1\user1",
    "i:0#.w|DOMAIN2\user2"
)

# Ensure log folder exists
$logFolder = [System.IO.Path]::GetDirectoryName($logFile)
if (!(Test-Path $logFolder)) {
    New-Item -ItemType Directory -Path $logFolder | Out-Null
}

Write-Host "Starting AD + SharePoint EnsureUser monitor loop..."

# Get SPWeb context once
try {
    $web = Get-SPWeb $webUrl
} catch {
    Write-Error "Failed to open SPWeb at $webUrl. Exiting."
    return
}

while ($true) {
    $timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
    $dc = "UNKNOWN"
    $ldapTime = "N/A"
    $nltestDc = "UNKNOWN"
    $nltestError = $null
    $logLines = @()

    try {
        # Get DC via .NET
        $domain = [System.DirectoryServices.ActiveDirectory.Domain]::GetCurrentDomain()
        $dc = $domain.PdcRoleOwner.Name

        # Time a basic LDAP user query
        $sw = [System.Diagnostics.Stopwatch]::StartNew()
        $searcher = New-Object System.DirectoryServices.DirectorySearcher
        $searcher.Filter = "(objectClass=user)"
        $searcher.PageSize = 1
        $result = $searcher.FindOne()
        $sw.Stop()
        $ldapTime = $sw.ElapsedMilliseconds
        $status = if ($result) { "OK" } else { "NoResult" }
    } catch {
        $status = "LDAP_FAIL: $($_.Exception.Message)"
    }

    try {
        # DC detection via nltest
        $nltestOutput = nltest /dsgetdc:$domainName 2>&1
        if ($LASTEXITCODE -eq 0) {
            $nltestDc = ($nltestOutput | Select-String "DC:" | ForEach-Object { ($_ -split ":")[1].Trim() })[0]
        } else {
            $nltestError = $nltestOutput -join " "
        }
    } catch {
        $nltestError = $_.Exception.Message
    }

    $logLines += "$timestamp | AD Site: $siteName | PDC: $dc | LDAP: ${ldapTime}ms | Status: $status | NLTEST_DC: $nltestDc"
    if ($nltestError) {
        $logLines += "$timestamp | NLTEST_ERR: $nltestError"
    }

    # Now run EnsureUser for each test user
    foreach ($loginName in $usersToCheck) {
        try {
            $eusw = [System.Diagnostics.Stopwatch]::StartNew()
            $spUser = $web.EnsureUser($loginName)
            $eusw.Stop()
            $eusElapsed = $eusw.ElapsedMilliseconds
            $eusStatus = "OK"
        } catch {
            $eusw.Stop()
            $eusElapsed = $eusw.ElapsedMilliseconds
            $eusStatus = "FAIL: $($_.Exception.Message)"
        }
        $logLines += "$timestamp | EnsureUser | $loginName | Time: ${eusElapsed}ms | Status: $eusStatus"
    }

    # Output and write to file
    $logLines | ForEach-Object {
        Write-Host $_
        Add-Content -Path $logFile -Value $_
    }

    Start-Sleep -Seconds $intervalSeconds
}

####

[
  {
    "UserProfile": {
      "EmployeeId": "THEIR_EMP_ID",
      "SamAccountName": "DOMAIN\\them",
      "EmailId": "them@example.com"
    },
    "SiteCollection": {
      "SPGuid": "actual-guid-from-site"
    }
  }
]

####

$bucket = "your-bucket-name"
$prefix = "out/"
$localDownloadPath = "C:\path\to\download"
$cutoffTime = (Get-Date).ToUniversalTime().AddDays(-1)

# Ensure download path exists
if (-not (Test-Path $localDownloadPath)) {
    New-Item -ItemType Directory -Path $localDownloadPath | Out-Null
}

# Get all files in the "out/" folder
$objects = aws s3api list-objects-v2 --bucket $bucket --prefix $prefix | ConvertFrom-Json

$matchedObjects = $objects.Contents |
    Where-Object {
        $_.Key -like "*reports*" -and
        ([datetime]$_.LastModified) -gt $cutoffTime
    }

foreach ($obj in $matchedObjects) {
    $s3Key = $obj.Key
    $relativePath = $s3Key.Substring($prefix.Length)  # Remove 'out/' from the start
    $localFilePath = Join-Path $localDownloadPath $relativePath
    $localDir = Split-Path $localFilePath

    if (-not (Test-Path $localDir)) {
        New-Item -ItemType Directory -Path $localDir -Force | Out-Null
    }

    Write-Host "Downloading $s3Key ‚Üí $localFilePath"
    aws s3 cp "s3://$bucket/$s3Key" "$localFilePath"
}
